{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1494bb0",
   "metadata": {},
   "source": [
    "<h1> QRT Grand Data Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe61add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"✅ Imports done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce07703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180245, 44) (7735, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>TS</th>\n",
       "      <th>ALLOCATION</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>RET_16</th>\n",
       "      <th>RET_15</th>\n",
       "      <th>RET_14</th>\n",
       "      <th>...</th>\n",
       "      <th>SIGNED_VOLUME_9</th>\n",
       "      <th>SIGNED_VOLUME_8</th>\n",
       "      <th>SIGNED_VOLUME_7</th>\n",
       "      <th>SIGNED_VOLUME_6</th>\n",
       "      <th>SIGNED_VOLUME_5</th>\n",
       "      <th>SIGNED_VOLUME_4</th>\n",
       "      <th>SIGNED_VOLUME_3</th>\n",
       "      <th>SIGNED_VOLUME_2</th>\n",
       "      <th>SIGNED_VOLUME_1</th>\n",
       "      <th>AVG_DAILY_TURNOVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DATE_0001</td>\n",
       "      <td>ALLOCATION_01</td>\n",
       "      <td>-0.002477</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>-0.001688</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.002217</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.016154</td>\n",
       "      <td>-1.011450</td>\n",
       "      <td>-1.171714</td>\n",
       "      <td>-0.729594</td>\n",
       "      <td>-1.208138</td>\n",
       "      <td>-1.215123</td>\n",
       "      <td>-0.848346</td>\n",
       "      <td>-0.642461</td>\n",
       "      <td>-0.203447</td>\n",
       "      <td>0.054324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DATE_0001</td>\n",
       "      <td>ALLOCATION_02</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>-0.005265</td>\n",
       "      <td>-0.004249</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896098</td>\n",
       "      <td>1.429419</td>\n",
       "      <td>0.946527</td>\n",
       "      <td>1.059767</td>\n",
       "      <td>0.988289</td>\n",
       "      <td>0.956915</td>\n",
       "      <td>0.943508</td>\n",
       "      <td>0.124168</td>\n",
       "      <td>0.081083</td>\n",
       "      <td>0.015669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DATE_0001</td>\n",
       "      <td>ALLOCATION_03</td>\n",
       "      <td>-0.005535</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>-0.007197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.889142</td>\n",
       "      <td>-0.939257</td>\n",
       "      <td>-0.980370</td>\n",
       "      <td>-0.863196</td>\n",
       "      <td>-0.839662</td>\n",
       "      <td>-0.882459</td>\n",
       "      <td>-1.172723</td>\n",
       "      <td>-0.863937</td>\n",
       "      <td>-0.695998</td>\n",
       "      <td>0.057961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DATE_0001</td>\n",
       "      <td>ALLOCATION_04</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>-0.004051</td>\n",
       "      <td>-0.001841</td>\n",
       "      <td>-0.005659</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.788263</td>\n",
       "      <td>-0.807971</td>\n",
       "      <td>-1.587942</td>\n",
       "      <td>-0.042083</td>\n",
       "      <td>-1.356051</td>\n",
       "      <td>-1.007006</td>\n",
       "      <td>-1.821786</td>\n",
       "      <td>-0.455660</td>\n",
       "      <td>-1.090989</td>\n",
       "      <td>0.096004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DATE_0001</td>\n",
       "      <td>ALLOCATION_05</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.005460</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>-0.003533</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326148</td>\n",
       "      <td>1.013100</td>\n",
       "      <td>0.362135</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.370484</td>\n",
       "      <td>-0.132558</td>\n",
       "      <td>-0.417645</td>\n",
       "      <td>-1.284208</td>\n",
       "      <td>-1.382900</td>\n",
       "      <td>0.005816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID         TS     ALLOCATION    RET_20    RET_19    RET_18    RET_17  \\\n",
       "0       0  DATE_0001  ALLOCATION_01 -0.002477  0.004826  0.005374 -0.001688   \n",
       "1       1  DATE_0001  ALLOCATION_02  0.006863 -0.005265 -0.004249  0.002686   \n",
       "2       2  DATE_0001  ALLOCATION_03 -0.005535  0.008541  0.005360 -0.002491   \n",
       "3       3  DATE_0001  ALLOCATION_04  0.003178 -0.001352 -0.004051 -0.001841   \n",
       "4       4  DATE_0001  ALLOCATION_05  0.003359 -0.003349 -0.005460  0.000416   \n",
       "\n",
       "     RET_16    RET_15    RET_14  ...  SIGNED_VOLUME_9  SIGNED_VOLUME_8  \\\n",
       "0 -0.000152 -0.000685 -0.002217  ...        -1.016154        -1.011450   \n",
       "1 -0.002638  0.003056  0.002712  ...         0.896098         1.429419   \n",
       "2  0.004679 -0.000848 -0.007197  ...        -0.889142        -0.939257   \n",
       "3 -0.005659  0.000627  0.006686  ...        -1.788263        -0.807971   \n",
       "4 -0.003533  0.000913  0.005088  ...         0.326148         1.013100   \n",
       "\n",
       "   SIGNED_VOLUME_7  SIGNED_VOLUME_6  SIGNED_VOLUME_5  SIGNED_VOLUME_4  \\\n",
       "0        -1.171714        -0.729594        -1.208138        -1.215123   \n",
       "1         0.946527         1.059767         0.988289         0.956915   \n",
       "2        -0.980370        -0.863196        -0.839662        -0.882459   \n",
       "3        -1.587942        -0.042083        -1.356051        -1.007006   \n",
       "4         0.362135         0.774670         0.370484        -0.132558   \n",
       "\n",
       "   SIGNED_VOLUME_3  SIGNED_VOLUME_2  SIGNED_VOLUME_1  AVG_DAILY_TURNOVER  \n",
       "0        -0.848346        -0.642461        -0.203447            0.054324  \n",
       "1         0.943508         0.124168         0.081083            0.015669  \n",
       "2        -1.172723        -0.863937        -0.695998            0.057961  \n",
       "3        -1.821786        -0.455660        -1.090989            0.096004  \n",
       "4        -0.417645        -1.284208        -1.382900            0.005816  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "display(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20604865",
   "metadata": {},
   "outputs": [],
   "source": [
    "RET_features = [f'RET_{i}' for i in range(1, 20)]\n",
    "SIGNED_VOLUME_features = [f'SIGNED_VOLUME_{i}' for i in range(1, 20)]\n",
    "TURNOVER_features = ['AVG_DAILY_TURNOVER']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50f2d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_test[RET_features\n",
    "    + SIGNED_VOLUME_features\n",
    "    + TURNOVER_features] = imputer.fit_transform(X_test[RET_features\n",
    "    + SIGNED_VOLUME_features\n",
    "    + TURNOVER_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908d9a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  X[\"TS_num\"] = X[\"TS\"].str.extract(\"(\\d+)\").astype(int)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_STD_{i}'] = X[RET_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_MEAN_{i}'] = X[VOL_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_STD_{i}'] = X[VOL_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_MEAN_{i}'] = X[RET_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_STD_{i}'] = X[RET_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_MEAN_{i}'] = X[VOL_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_STD_{i}'] = X[VOL_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_MEAN_{i}'] = X[RET_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_STD_{i}'] = X[RET_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_MEAN_{i}'] = X[VOL_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_STD_{i}'] = X[VOL_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_MEAN_{i}'] = X[RET_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_STD_{i}'] = X[RET_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_MEAN_{i}'] = X[VOL_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_STD_{i}'] = X[VOL_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_MEAN_{i}'] = X[RET_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'RET_STD_{i}'] = X[RET_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_MEAN_{i}'] = X[VOL_features[:i]].mean(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[f'VOL_STD_{i}'] = X[VOL_features[:i]].std(axis=1)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[\"RET_TREND_5\"] = X[\"RET_20\"] - X[\"RET_15\"]\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[\"VOL_TREND_5\"] = X[\"SIGNED_VOLUME_20\"] - X[\"SIGNED_VOLUME_15\"]\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[\"TS_num\"] = X[\"TS\"].str.extract(\"(\\d+)\").astype(int)\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/518491733.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[\"VOL_PERF_RATIO\"] = X[VOL_features].mean(axis=1) / (X[RET_features].std(axis=1) + 1e-9)\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(X):\n",
    "    RET_features = [f'RET_{i}' for i in range(1, 21)]\n",
    "    VOL_features = [f'SIGNED_VOLUME_{i}' for i in range(1, 21)]\n",
    "    TURNOVER_features = ['AVG_DAILY_TURNOVER']\n",
    "\n",
    "    for i in range(2, 21):\n",
    "        X[f'RET_MEAN_{i}'] = X[RET_features[:i]].mean(axis=1)\n",
    "        X[f'RET_STD_{i}'] = X[RET_features[:i]].std(axis=1)\n",
    "        X[f'VOL_MEAN_{i}'] = X[VOL_features[:i]].mean(axis=1)\n",
    "        X[f'VOL_STD_{i}'] = X[VOL_features[:i]].std(axis=1)\n",
    "\n",
    "    # Trends\n",
    "    X[\"RET_TREND_5\"] = X[\"RET_20\"] - X[\"RET_15\"]\n",
    "    X[\"VOL_TREND_5\"] = X[\"SIGNED_VOLUME_20\"] - X[\"SIGNED_VOLUME_15\"]\n",
    "\n",
    "    # Temporal drift encoding\n",
    "    X[\"TS_num\"] = X[\"TS\"].str.extract(\"(\\d+)\").astype(int)\n",
    "    X[\"VOL_PERF_RATIO\"] = X[VOL_features].mean(axis=1) / (X[RET_features].std(axis=1) + 1e-9)\n",
    "\n",
    "    return X, RET_features, VOL_features, TURNOVER_features\n",
    "\n",
    "X_train, RET_features, VOL_features, TURNOVER_features = feature_engineering(X_train)\n",
    "X_test, _, _, _ = feature_engineering(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "837073bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/991618047.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[\"ALLOCATION_enc\"] = alloc_encoder.transform(X_test[[\"ALLOCATION\"]])\n"
     ]
    }
   ],
   "source": [
    "def oof_target_encoding(X, y, col, n_splits=5):\n",
    "    X = X.copy().reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    X[f\"{col}_enc\"] = np.nan\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        enc = TargetEncoder(smoothing=0.3)\n",
    "        enc.fit(X.iloc[train_idx][[col]], (y.iloc[train_idx] > 0).astype(int))\n",
    "        X.loc[val_idx, f\"{col}_enc\"] = enc.transform(X.iloc[val_idx][[col]]).values.flatten()\n",
    "\n",
    "    enc.fit(X[[col]], (y > 0).astype(int))\n",
    "    return X, enc\n",
    "\n",
    "X_train, alloc_encoder = oof_target_encoding(X_train, y_train[\"target\"], \"ALLOCATION\")\n",
    "X_test[\"ALLOCATION_enc\"] = alloc_encoder.transform(X_test[[\"ALLOCATION\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0a9af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ret = StandardScaler()\n",
    "scaler_vol = StandardScaler()\n",
    "\n",
    "X_train_ret = scaler_ret.fit_transform(X_train[RET_features])\n",
    "X_test_ret = scaler_ret.transform(X_test[RET_features])\n",
    "\n",
    "X_train_vol = scaler_vol.fit_transform(X_train[VOL_features])\n",
    "X_test_vol = scaler_vol.transform(X_test[VOL_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a11a9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x147ae8e10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_autoencoder(input_dim, latent_dim=5):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoded = Dense(12, activation='relu')(inp)\n",
    "    encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "    decoded = Dense(12, activation='relu')(encoded)\n",
    "    out = Dense(input_dim, activation='linear')(decoded)\n",
    "    return Model(inp, out), Model(inp, encoded)\n",
    "\n",
    "autoencoder_ret, encoder_ret = build_autoencoder(20, latent_dim=5)\n",
    "autoencoder_ret.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "autoencoder_ret.fit(\n",
    "    X_train_ret, X_train_ret,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f6d96d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5633/5633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171us/step\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/3045747527.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[ret_latent_cols] = X_test_ret_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/3045747527.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[ret_latent_cols] = X_test_ret_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/3045747527.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[ret_latent_cols] = X_test_ret_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/3045747527.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[ret_latent_cols] = X_test_ret_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/3045747527.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[ret_latent_cols] = X_test_ret_latent\n"
     ]
    }
   ],
   "source": [
    "X_train_ret_latent = encoder_ret.predict(X_train_ret)\n",
    "X_test_ret_latent = encoder_ret.predict(X_test_ret)\n",
    "\n",
    "ret_latent_cols = [f\"RET_LATENT_{i}\" for i in range(X_train_ret_latent.shape[1])]\n",
    "X_train[ret_latent_cols] = X_train_ret_latent\n",
    "X_test[ret_latent_cols] = X_test_ret_latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aa47369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5633/5633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170us/step\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/1872457523.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[vol_latent_cols] = X_test_vol_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/1872457523.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[vol_latent_cols] = X_test_vol_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/1872457523.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[vol_latent_cols] = X_test_vol_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/1872457523.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[vol_latent_cols] = X_test_vol_latent\n",
      "/var/folders/tp/p2fdv61s7979qs0rlp6mh9qw0000gn/T/ipykernel_76339/1872457523.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test[vol_latent_cols] = X_test_vol_latent\n"
     ]
    }
   ],
   "source": [
    "autoencoder_vol, encoder_vol = build_autoencoder(20, latent_dim=5)\n",
    "autoencoder_vol.compile(optimizer='adam', loss='mse')\n",
    "autoencoder_vol.fit(\n",
    "    X_train_vol, X_train_vol,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "X_train_vol_latent = encoder_vol.predict(X_train_vol)\n",
    "X_test_vol_latent = encoder_vol.predict(X_test_vol)\n",
    "\n",
    "vol_latent_cols = [f\"VOL_LATENT_{i}\" for i in range(X_train_vol_latent.shape[1])]\n",
    "X_train[vol_latent_cols] = X_train_vol_latent\n",
    "X_test[vol_latent_cols] = X_test_vol_latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1e76a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(contamination=0.02, random_state=42)\n",
    "mask = iso.fit_predict(X_train[ret_latent_cols + vol_latent_cols]) == 1\n",
    "X_train_clean = X_train[mask]\n",
    "y_train_clean = y_train.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e64875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = ret_latent_cols + vol_latent_cols + [\"ALLOCATION_enc\", \"AVG_DAILY_TURNOVER\"]\n",
    "\n",
    "scaler_final = StandardScaler()\n",
    "X_train_scaled = scaler_final.fit_transform(X_train_clean[features_final])\n",
    "X_test_scaled = scaler_final.transform(X_test[features_final])\n",
    "\n",
    "ridge = RidgeClassifier(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, (y_train_clean[\"target\"] > 0).astype(int))\n",
    "\n",
    "y_pred_test = ridge.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b593ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier de soumission généré avec succès !\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ROW_ID\": X_test[\"ROW_ID\"],\n",
    "    \"target\": y_pred_test\n",
    "})\n",
    "submission.to_csv(\"submission_autoencoder_ridge.csv\", index=False)\n",
    "print(\"✅ Fichier de soumission généré avec succès !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
